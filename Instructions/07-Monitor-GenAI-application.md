---
lab:
  title: 監視您的生成式 AI 應用程式
  description: 了解如何監視和已部署模型之間的互動，並獲得深入解析，了解如何使用您的生成式 AI 應用程式將其使用方式最佳化。
---

# 監視您的生成式 AI 應用程式

本練習大約需要 **30** 分鐘的時間。

> **注意**：本練習假設您對 Azure AI Foundry 有一定的瞭解，因此有些說明刻意不那麼詳盡，以鼓勵更積極地探索和實踐學習。

## 簡介

在本練習中，您將啟用對聊天完成應用程式的監視並在 Azure 監視器中檢視其效能。 您可以與已部署的模型進行互動以產生資料，透過生成式 AI 應用程式儀表板深入解析檢視產生的資料，並設定警示以幫助最佳化模型部署。

## 設定環境

若要完成本練習中的工作，您需要：

- Azure AI Foundry 專案；
- 已部署的模型（例如 GPT-4o）；
- 已連線的 Application Insights 資源。

### 在 Azure AI Foundry 專案中部署模型

若要快速設定 Azure AI Foundry 專案，以下提供使用 Azure AI Foundry 入口網站 UI 的簡單指示。

1. 在網頁瀏覽器中，開啟 [Azure AI Foundry 入口網站](https://ai.azure.com) 於`https://ai.azure.com` 並使用您的 Azure 認證登入。
1. 在首頁的 [探索模型和功能]**** 區段中搜尋 `gpt-4o` 模型。我們會在專案中使用這個模型。
1. 在搜尋結果中選取 **gpt-4o** 模型以查看其詳細資料，然後在該模型的頁面頂端選取 [使用此模型]****。
1. 當系統提示您建立專案時，請輸入您專案的有效名稱，然後展開 [進階選項]****。
1. 選取 [自訂]****，然後為專案指定下列設定：
    - **Azure AI Foundry 資源**：*Azure AI Foundry 資源的有效名稱*
    - **訂用帳戶**：您的 Azure 訂用帳戶**
    - **資源群組**：建立或選取資源群組**
    - **地區**：*選取任何 **AI 服務支援的位置***\*

    > \*部分 Azure AI 資源受區域模型配額限制。 在練習後期，若超過配額限制，您可能需要在不同區域建立另一個資源。

1. 選取 [建立]****，並等待您的專案建立完畢，這包括您選取的 gpt-4 模型部署。
1. 在左側瀏覽窗格中選取 [概觀]****，以查看專案的主頁面。
1. 在 [端點和金鑰]**** 區域中，確認已選取 **Azure AI Foundry** 程式庫，並檢視 **Azure AI Foundry 專案端點**。
1. 將端點**儲存**在記事本中。 請使用此端點在用戶端應用程式中連線到您的專案。

### 連接 Application Insights

將 Application Insights 連線到 Azure AI Foundry 中的專案，開始收集資料並監視。

1. 使用左側的功能表，然後選取 [追蹤]**** 頁面。
1. **建立新的** Application Insights 資源以連線到您的應用程式。
1. 輸入 Application Insights 資源名稱，然後選取 [建立]****。

Application Insights 現在已連線到您的專案，並開始收集資料以進行分析。

## 與已部署的模型互動

您將使用 Azure Cloud Shell 設定與 Azure AI Foundry 專案的連線，以程式設計方式與已部署的模型互動。 這可讓您將提示傳送至模型並產生監視資料。

### 透過 Cloud Shell 與模型連線

首先，擷取為了與您的模型互動而要驗證的必要資訊。 然後，您將存取 Azure Cloud Shell 並更新設定，以將提供的提示傳送至您自己的已部署模型。

1. 開啟一個新的瀏覽器索引標籤（保持 Azure AI Foundry 入口網站在現有索引標籤中開啟）。
1. 在新索引標籤中，瀏覽到 `https://portal.azure.com` 的 [Azure 入口網站](https://portal.azure.com)；如果出現提示，請使用您的 Azure 認證登入。
1. 使用頁面頂部搜尋欄右側的 **[\>_]** 按鈕在 Azure 入口網站中建立一個新的 Cloud Shell，並選擇 ***PowerShell 環境*** (訂用帳戶中沒有儲存體)。
1. 在 Cloud Shell 工具列中，在 [設定]**** 功能表中，選擇 [移至傳統版本]****。

    **<font color="red">繼續之前，請先確定您已切換成 Cloud Shell 傳統版本。</font>**

1. 在 Cloud Shell 窗格中，輸入並執行下列命令：

    ```
    rm -r mslearn-genaiops -f
    git clone https://github.com/microsoftlearning/mslearn-genaiops mslearn-genaiops
    ```

    此命令會複製 GitHub 存放庫，其中包含此練習的程式碼檔案。

    > **秘訣**：當您將命令貼到 Cloud Shell 中時，輸出可能會佔用大量的螢幕緩衝區。 您可以透過輸入 `cls` 命令來清除螢幕，以便更輕鬆地專注於每個工作。

1. 複製存放庫之後，瀏覽至包含應用程式碼檔案的資料夾：  

    ```
   cd mslearn-genaiops/Files/07
    ```

1. 在 Cloud Shell 命令列窗格中，輸入下列命令來安裝您需要的程式庫：

    ```
   python -m venv labenv
   ./labenv/bin/Activate.ps1
   pip install python-dotenv openai azure-identity azure-ai-projects opentelemetry-instrumentation-openai-v2 azure-monitor-opentelemetry
    ```

1. 輸入以下命令，開啟已提供的設定檔：

    ```
   code .env
    ```

    程式碼編輯器中會開啟檔案。

1. 在程式碼檔案中：

    1. 在程式碼檔案中，以專案的端點 (從 Azure AI Foundry 入口網站中的專案 [概觀]**** 頁面複製) 取代 **your_project_endpoint** 預留位置。
    1. 將 **your_model_deployment** 預留位置替換為您指派給 GPT-4o 模型部署的名稱（預設為 `gpt-4o`）。

1. *取代預留位置後*，在程式碼編輯器中使用 **CTRL+S** 命令或**按下滑鼠右鍵 > [儲存]** 來**儲存變更**，然後使用 **CTRL+Q** 命令或**按下滑鼠右鍵 > [結束]** 來關閉程式碼編輯器，同時保持 Cloud Shell 命令列開啟。

### 將提示傳送至已部署的模型

您現在會執行多個指令碼，將不同的提示傳送至已部署的模型。 這些互動會產生稍後可在 Azure 監視器中觀察的資料。

1. 執行下列命令以**檢視已提供的第一個指令碼**：

    ```
   code start-prompt.py
    ```

1. 在 Cloud Shell 命令行窗格中，輸入下列命令以登錄 Azure。

    ```
   az login
    ```

    **<font color="red">即使 Cloud Shell 工作階段已經過驗證，您還是必須登錄 Azure。</font>**

    > **注意**：在大部分情況下，只要使用 *az 登入*即可。 不過，如果您在多個租用戶中擁有訂用帳戶，您可能需要使用 *--tenant* 參數指定租用戶。 如需詳細資料，請參閱[使用 Azure CLI 以互動方式登入 Azure](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)。
    
1. 出現提示時，請遵循指示，在新的索引標籤中開啟登入頁面，然後輸入所提供的驗證碼和您的 Azure 認證。 接著，在命令行中完成登入流程。如果出現提示，請選取包含 Azure AI Foundry 中樞的訂用帳戶。
1. 登入之後，請輸入下列命令以執行應用程式：

    ```
   python start-prompt.py
    ```

    模型會產生回應，這會使用 Application Insights 擷取以進一步分析。 讓我們改變提示來探索其效果。

1. **開啟並檢閱指令碼**，其中提示會指示模型 **只回答一個句子和清單**：

    ```
   code short-prompt.py
    ```

1. 在命令列中輸入下列命令，以**執行指令碼**：

    ```
   python short-prompt.py
    ```

1. 下一個指令碼有類似的目標，但包含**系統訊息**中輸出的指示，而不是使用者訊息：

    ```
   code system-prompt.py
    ```

1. 在命令列中輸入下列命令，以**執行指令碼**：

    ```
   python system-prompt.py
    ```

1. 最後，讓我們嘗試執行含有**太多權杖**的提示來觸發錯誤：

    ```
   code error-prompt.py
    ```

1. 在命令列中輸入下列命令，以**執行指令碼**。 請注意，您**很可能遇到錯誤！**

    ```
   python error-prompt.py
    ```

既然您已與模型互動，您可以檢閱 Azure 監視器中的資料。

> **注意**：監視資料可能需要幾分鐘的時間才會顯示在 Azure 監視器中。

## 檢視 Azure 監視器中的監視資料

若要檢視從模型互動收集的資料，您將存取連結到 Azure 監視器中活頁簿的儀表板。

### 從 Azure AI Foundry 入口網站瀏覽至 Azure 監視器

1. 在開啟 **Azure AI Foundry 入口網站**的情況下，瀏覽至瀏覽器中的索引標籤。
1. 使用左側功能表，選取 [監視]****。
1. 選取 [資源使用狀況]****，檢閱您已部署模型互動狀況的摘要資料。

> **注意**：您也可以在 [監視] 頁面底部選取 [Azure 監視器計量瀏覽器]****，取得所有可用計量的完整檢視。 此連結會在新的索引標籤中開啟 Azure 監視器。

## 解譯監視計量

現在是時候深入探討資料，並開始解譯它告訴您的內容。

### 檢閱權杖使用方式

首先關注**權杖使用方式**章節並檢閱以下指標：

- **要求總數**：單獨推斷要求的數量，即模型被呼叫的次數。

> 有助於分析輸送量和瞭解每次呼叫的平均成本。

- **權杖總數**：提示權杖和完成權杖的總和。

> 計費和效能的最重要指標，因為它會導致延遲和成本。

- **提示權杖計數**：所有模型呼叫中輸入 (您傳送的提示) 中使用的權杖總數。

> 可以將其視為向模型*提出*問題的成本。

- **完成權杖計數**：模型作為輸出傳回的權杖數，即回應的長度。

> 產生的完成權杖通常代表大部分權杖使用情況和成本，特別是對於長或冗長的答案。

### 比較個別提示

1. 使用左側功能表，選取 [追蹤]****。 展開每個 **generate_completion** 生成式 AI 範圍，查看其子系範圍。 每個提示會以新的資料列表示。 檢閱並比較以下欄的內容：

- **輸入**：顯示傳送至模型的使用者訊息。

> 使用此欄來評估哪些提示公式是有效的或有問題的。公式

- **輸出**：包含模型的回應。

> 使用它來評估詳細程度、相關性和一致性。 特別是在權杖計數和持續時間方面。

- **持續時間**：顯示模型回應所花費的時間，以毫秒為單位。

> 跨列比較以探索哪些提示模式會導致更長的處理時間。

- **成功**：模型呼叫成功或失敗。

> 使用此項目來識別有問題的提示或設定錯誤。 最後一個提示可能失敗，因為提示太長。

## (選用) 建立警示

如果您有額外的時間，請嘗試設定警示，以在模型延遲超過特定閾值時通知您。 這是一項旨在挑戰您的練習，這意味著說明故意不太詳細。

- 在 Azure 監視器中，為您的 Azure AI Foundry 專案和模型建立**新的警示規則**。
- 選擇一個指標，例如**請求時長（毫秒）**，並定義一個閾值（例如，大於 4000 毫秒）。
- 建立**新的動作群組** ，以定義您將如何收到通知。

警示透過建立主動監視幫助您做好生產準備。 您設定的警示將取決於您的專案的優先順序以及您的團隊決定如何衡量和減輕風險。

## 哪裡可以找到其他實驗室

您可以在 [Azure AI Foundry 學習入口網站](https://ai.azure.com)中探索其他實驗和練習，或參閱課程的**實驗部分**瞭解其他可用的活動。
