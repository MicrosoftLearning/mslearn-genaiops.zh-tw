---
lab:
  title: 監視您的生成式 AI 應用程式
---

# 監視您的生成式 AI 應用程式

本練習大約需要 **30** 分鐘的時間。

> **注意**：本練習假設您對 Azure AI Foundry 有一定的瞭解，因此有些說明刻意不那麼詳盡，以鼓勵更積極地探索和實踐學習。

## 簡介

在本練習中，您將啟用對聊天完成應用程式的監視並在 Azure 監視器中檢視其效能。 您可以與已部署的模型進行互動以產生資料，透過生成式 AI 應用程式儀表板深入解析檢視產生的資料，並設定警示以幫助最佳化模型部署。

## 1. 設定環境

若要完成本練習中的工作，您需要：

- Azure AI Foundry 中樞；
- Azure AI Foundry 專案；
- 已部署的模型（例如 GPT-4o）；
- 已連線的 Application Insights 資源。

### A. 建立 AI Foundry 中樞與專案

若要快速設定中樞和專案，以下提供使用 Azure AI Foundry 入口網站 UI 的簡單指示。

1. 瀏覽至 Azure AI Foundry 入口網站：開啟 [https://ai.azure.com](https://ai.azure.com)。
1. 使用您的 Azure 認證進行登入。
1. 建立專案：
    1. 瀏覽至 [所有中樞 + 專案]****。
    1. 選取 [+ 新增專案]****。
    1. 輸入**專案名稱**。
    1. 出現提示時， **請建立新的中樞**。
    1. 自訂中樞：

        1. 選取適當的 [訂用帳戶]****、[資源群組]** **和 [位置] 等****。
        1. 連結**新的 Azure AI 服務**資源（跳過 AI 搜尋）。

    1. 檢閱並選取 [建立]****。

1. **請等候部署完成**（大約 1-2 分鐘）。

### B. 部署模型

若要產生您可以監視的資料，您必須先部署模型並與其互動。 指示會要求您部署 GPT-4o 模型，但**您可以使用 Azure OpenAI 服務集合中可供您使用的任何模型**。

1. 使用左側的功能表，在 [我的資產]**** 中，選取 [模型 + 端點]**** 頁面。
1. 部署**基本模型**，然後選擇 [gpt-4o]****。
1. **自訂部署詳細資料**。
1. 將 [容量]**** 設定為 [每分鐘 5K 個權杖 (TPM)]****。

中樞和專案已就緒，並會自動佈建所有必要的 Azure 資源。

### C. 連接 Application Insights

將 Application Insights 連線到 Azure AI Foundry 中的專案，開始收集資料並監視。

1. 在 Azure AI Foundry 入口網站中打開您的專案。
1. 使用左側的功能表，然後選取 [追蹤]**** 頁面。
1. **建立新的** Application Insights 資源以連線到您的應用程式。
1. 輸入 **Application Insights 資源名稱**。

Application Insights 現在已連線到您的專案，並開始收集資料以進行分析。

## 2. 與已部署的模型互動

您將使用 Azure Cloud Shell 設定與 Azure AI Foundry 專案的連線，以程式設計方式與已部署的模型互動。 這可讓您將提示傳送至模型並產生監視資料。

### A. 透過 Cloud Shell 與模型連線

首先，擷取為了與您的模型互動而要驗證的必要資訊。 然後，您將存取 Azure Cloud Shell 並更新設定，以將提供的提示傳送至您自己的已部署模型。

1. 在 Azure AI Foundry 入口網站中，檢視專案的**概觀**頁面。
1. 在 [專案詳細資料]**** 區域中，記下 [專案連接字串]****。
1. 將字串**儲存**在記事本中。 您將使用此連接字串連線到用戶端應用程式中的專案。
1. 開啟一個新的瀏覽器索引標籤（保持 Azure AI Foundry 入口網站在現有索引標籤中開啟）。
1. 在新索引標籤中，瀏覽到 `https://portal.azure.com` 的 [Azure 入口網站](https://portal.azure.com)；如果出現提示，請使用您的 Azure 認證登入。
1. 使用頁面頂部搜尋欄右側的 **[\>_]** 按鈕在 Azure 入口網站中建立一個新的 Cloud Shell，並選擇 ***PowerShell 環境*** (訂用帳戶中沒有儲存體)。
1. 在 Cloud Shell 工具列中，在 [設定]**** 功能表中，選擇 [移至傳統版本]****。

    **<font color="red">繼續之前，請先確定您已切換成 Cloud Shell 傳統版本。</font>**

1. 在 Cloud Shell 窗格中，輸入並執行下列命令：

    ```
    rm -r mslearn-genaiops -f
    git clone https://github.com/microsoftlearning/mslearn-genaiops mslearn-genaiops
    ```

    此命令會複製 GitHub 存放庫，其中包含此練習的程式碼檔案。

1. 複製存放庫之後，瀏覽至包含應用程式碼檔案的資料夾：  

    ```
   cd mslearn-genaiops/Files/07
    ```

1. 在 Cloud Shell 命令列窗格中，輸入下列命令來安裝您需要的程式庫：

    ```
   python -m venv labenv
   ./labenv/bin/Activate.ps1
   pip install python-dotenv azure-identity azure-ai-projects azure-ai-inference azure-monitor-opentelemetry
    ```

1. 輸入以下命令，開啟已提供的設定檔：

    ```
   code .env
    ```

    程式碼編輯器中會開啟檔案。

1. 在程式碼檔案中：

    1. 將 **your_project_connection_string** 預留位置替換為專案的連接字串（從 Azure AI Foundry 入口網站中的專案**概觀**頁面複製）。
    1. 將 **your_model_deployment** 預留位置替換為您指派給 GPT-4o 模型部署的名稱（預設為 `gpt-4o`）。

1. 替換預留位置*之後*，請在程式碼編輯器中使用 **CTRL+S** 命令或**按右鍵 > [儲存]** 來**儲存變更**。

### B. 將提示傳送至已部署的模型

您現在會執行多個指令碼，將不同的提示傳送至已部署的模型。 這些互動會產生稍後可在 Azure 監視器中觀察的資料。

1. 執行下列命令以**檢視已提供的第一個指令碼**：

    ```
   code start-prompt.py
    ```

1. 在程式碼編輯器下的 Cloud Shell 命令列窗格中，輸入下列命令來**執行指令碼**：

    ```
   python start-prompt.py
    ```

    模型會產生回應，這會使用 Application Insights 擷取以進一步分析。 讓我們改變提示來探索其效果。

1. **開啟並檢閱指令碼**，其中提示會指示模型**只回答一個句子和清單**：

    ```
   code short-prompt.py
    ```

1. 在命令列中輸入下列命令，以**執行指令碼**：

    ```
   python short-prompt.py
    ```

1. 下一個指令碼有類似的目標，但包含**系統訊息**中輸出的指示，而不是使用者訊息：

    ```
   code system-prompt.py
    ```

1. 在命令列中輸入下列命令，以**執行指令碼**：

    ```
   python system-prompt.py
    ```

1. 最後，讓我們嘗試執行含有**太多權杖**的提示來觸發錯誤：

    ```
   code error-prompt.py
    ```

1. 在命令列中輸入下列命令，以**執行指令碼**。 請注意，您**很可能遇到錯誤！**

    ```
   python error-prompt.py
    ```

既然您已與模型互動，您可以檢閱 Azure 監視器中的資料。

> **注意**：監視資料可能需要幾分鐘的時間才會顯示在 Azure 監視器中。

## 4. 檢視 Azure 監視器中的監視資料

若要檢視從模型互動收集的資料，您將存取連結到 Azure 監視器中活頁簿的儀表板。

### A. 從 Azure AI Foundry 入口網站瀏覽至 Azure 監視器

1. 在開啟 **Azure AI Foundry 入口網站**的情況下，瀏覽至瀏覽器中的索引標籤。
1. 使用左側功能表，選取 [追蹤]****。
1. 選取頂端指出 [查看您的生成式 AI 應用程式儀表板深入解析]**** 的連結。 此連結會在新的索引標籤中開啟 Azure 監視器。
1. 檢閱**概觀**，提供與已部署模型互動的摘要資料。

## 5. 解譯 Azure 監視器中的監視計量

現在是時候深入探討資料，並開始解譯它告訴您的內容。

### A. 檢閱權杖使用方式

首先關注**權杖使用方式**章節並檢閱以下指標：

- **提示權杖**：所有模型呼叫中輸入（您傳送的提示）中使用的權杖總數。

> 可以將其視為向模型*提出*問題的成本。

- **完成權杖**：模型作為輸出返回的權杖數，本質上是回應的長度。

> 產生的完成權杖通常代表大部分權杖使用情況和成本，特別是對於長或冗長的答案。

- **總權杖數**：提示權杖和完成權杖的總和。

> 計費和效能的最重要指標，因為它會導致延遲和成本。

- **總呼叫次數**：單獨推理請求的數量，即模型被呼叫的次數。

> 有助於分析輸送量和瞭解每次呼叫的平均成本。

### B. 比較個別提示

向下捲動以找到 **Gen AI Spans**，它以表格形式顯示，其中每個提示都表示為一行新資料。 檢閱並比較以下欄的內容：

- **狀態**：模型呼叫成功或失敗。

> 使用此項目來識別有問題的提示或設定錯誤。 最後一個提示可能失敗，因為提示太長。

- **持續時間**：顯示模型回應所花費的時間，以毫秒為單位。

> 跨列比較以探索哪些提示模式會導致更長的處理時間。

- **輸入**：顯示傳送至模型的使用者訊息。

> 使用此欄來評估哪些提示公式是有效的或有問題的。公式

- **系統**：顯示提示中使用的系統訊息（如果有的話）。

> 比較項目以評估使用或變更系統訊息的影響。

- **輸出**：包含模型的回應。

> 使用它來評估詳細程度、相關性和一致性。 特別是在權杖計數和持續時間方面。

## 6. （選擇性） 建立警示

如果您有額外的時間，請嘗試設定警示，以在模型延遲超過特定閾值時通知您。 這是一項旨在挑戰您的練習，這意味著說明故意不太詳細。

- 在 Azure 監視器中，為您的 Azure AI Foundry 專案和模型建立**新的警示規則**。
- 選擇一個指標，例如**請求時長（毫秒）**，並定義一個閾值（例如，大於 4000 毫秒）。
- 建立**新的動作群組** ，以定義您將如何收到通知。

警示透過建立主動監視幫助您做好生產準備。 您設定的警示將取決於您的專案的優先順序以及您的團隊決定如何衡量和減輕風險。

## 哪裡可以找到其他實驗室

您可以在 [Azure AI Foundry 學習入口網站](https://ai.azure.com)中探索其他實驗和練習，或參閱課程的**實驗部分**瞭解其他可用的活動。
