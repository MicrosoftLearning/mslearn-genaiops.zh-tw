{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare models\n",
    "\n",
    "In this notebook, you'll run sample prompts through chat completion requests sent to two of your deployed GPT models. Later, you'll verify some of the metrics available on the usage of your Azure OpenAI resources and determine which model is best suited for your use case.\n",
    "\n",
    "## Before you start\n",
    "\n",
    "You'll need the latest version of the **openai** library to run the code in this notebook. Additionally, you'll need the **azure-indentity** library to authenticate your requests for metric values submitted using the Azure Monitor API and the **matplotlib** library to test the output code generated by your models in this exercise. Run the cell below to install the aforementioned libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the latest version of the openai library using pip\n",
    "! pip install openai -U\n",
    "\n",
    "# Install the Azure Identity library using pip\n",
    "! pip install azure-identity\n",
    "\n",
    "# Install the matplotlib library using pip\n",
    "! pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need to define the values that will be used when submitting a chat completion request through the API endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base URL for your Azure OpenAI Service endpoint\n",
    "# Replace 'Your Azure OpenAI Service Endpoint' with your actual endpoint URL obtained previously\n",
    "api_base = 'Your Azure OpenAI Service Endpoint'\n",
    "\n",
    "# Define the API key for your Azure OpenAI Service\n",
    "# Replace 'Your Azure OpenAI Service API Key' with your actual API key obtained previously\n",
    "api_key = 'Your Azure OpenAI Service API Key'\n",
    "\n",
    "# Define the names of the models deployed in your Azure OpenAI Service\n",
    "model_name1 = 'gpt-4o'\n",
    "model_name2 = 'gpt-4o-mini'\n",
    "\n",
    "# Define the API version to use for the Azure OpenAI Service\n",
    "api_version = '2024-08-01-preview'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you need to encode the image used in this exercise into a data URL. This URL will be used to embed the image directly in the chat completion request together with the text prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the base64 module, which provides functions for encoding and decoding data in base64 format\n",
    "import base64\n",
    "\n",
    "# Import the guess_type function from the mimetypes module\n",
    "# This function is used to guess the MIME type of a file based on its filename or URL\n",
    "from mimetypes import guess_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode a local image into a data URL\n",
    "def local_image_to_data_url(image_path):\n",
    "    # Guess the MIME type of the image based on the file extension\n",
    "    mime_type, _ = guess_type(image_path)\n",
    "    if mime_type is None:\n",
    "        mime_type = 'application/octet-stream'  # Default MIME type if none is found\n",
    "\n",
    "    # Read and encode the image file\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    # Construct the data URL\n",
    "    return f\"data:{mime_type};base64,{base64_encoded_data}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the image file\n",
    "image_path = './imgs/demo.png'\n",
    "\n",
    "# Convert the local image to a data URL using the local_image_to_data_url function\n",
    "data_url = local_image_to_data_url(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you'll create two instances of the AzureOpenAI client, one for each model, to interact with your Azure OpenAI Service and obtain the chat completion responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the AzureOpenAI class from the openai library\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Create two instances of the AzureOpenAI client to interact with Azure's OpenAI Service\n",
    "client1 = AzureOpenAI(\n",
    "    # Use the API key for authentication\n",
    "    api_key=api_key,  \n",
    "    \n",
    "    # Specify the API version to use\n",
    "    api_version=api_version,\n",
    "    \n",
    "    # Construct the base URL for the deployment using the provided API base and deployment name\n",
    "    base_url=f\"{api_base}openai/deployments/{model_name1}\",\n",
    ")\n",
    "\n",
    "client2 = AzureOpenAI(\n",
    "    api_key=api_key,  \n",
    "    api_version=api_version,    \n",
    "    base_url=f\"{api_base}openai/deployments/{model_name2}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the messages to send to the models\n",
    "messages1=[\n",
    "    { \n",
    "        \"role\": \"user\", \n",
    "        \"content\": [  \n",
    "            { \n",
    "                # Specify the type of content as text\n",
    "                \"type\": \"text\", \n",
    "                    \n",
    "                # Provide the text content for the model to process\n",
    "                \"text\": \"Please create Python code for image, and use plt to save the new picture under imgs/ and name it gpt-4o.jpg.\" \n",
    "            },\n",
    "            { \n",
    "                # Specify the type of content as an image URL\n",
    "                \"type\": \"image_url\",\n",
    "                  \n",
    "                # Provide the image URL for the model to process\n",
    "                \"image_url\": {\n",
    "                    \"url\": data_url\n",
    "                }\n",
    "            }\n",
    "        ] \n",
    "    } \n",
    "]\n",
    "\n",
    "messages2=[\n",
    "    { \n",
    "        \"role\": \"user\", \n",
    "        \"content\": [  \n",
    "            { \n",
    "                \"type\": \"text\", \n",
    "                \"text\": \"Please create Python code for image, and use plt to save the new picture under imgs/ and name it gpt-4o-mini.jpg.\" \n",
    "            },\n",
    "            { \n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": data_url\n",
    "                }\n",
    "            }\n",
    "        ] \n",
    "    } \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the chat completion requests using the AzureOpenAI clients\n",
    "response1 = client1.chat.completions.create(\n",
    "    # Specify the model to use for generating the response\n",
    "    model=model_name1,\n",
    "    \n",
    "    # Define the messages to send to the model\n",
    "    messages=messages1,\n",
    "    \n",
    "    # Set the maximum number of tokens to generate in the response\n",
    "    max_tokens=2000 \n",
    ")\n",
    "\n",
    "response2 = client2.chat.completions.create(\n",
    "    model=model_name2,\n",
    "    messages=messages2,\n",
    "    max_tokens=2000 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The response contains multiple choices, and we are accessing the first one as our result\n",
    "result1 = response1.choices[0].message.content\n",
    "result2 = response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables `result1` and `result2` now contain the content of the first choice from their respective responses. This content is the generated text or code from the model based on the input messages. You can print each result, copy the code block generated within them, run each of the codes in a new code cell and compare their outputs. Are the scripts and outputs in any way different? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can submit more requests and have the code modified. It will also further demonstrate the difference between the models and make the metrics observed later on more significant. However, to make sure that the models keep track of the prompt history, we need to append their responses and the new prompts to the `messages` variables that we've been using so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the responses to the messages as an Assistant Role\n",
    "messages1.append({\"role\": \"assistant\", \"content\": result1})\n",
    "messages2.append({\"role\": \"assistant\", \"content\": result2})\n",
    "\n",
    "# Define the new prompt that will develop the chat completion further\n",
    "new_prompt = \"Add a legend to the plot replacing the labels\"\n",
    "\n",
    "# Add the user's question to the messages as a User Role\n",
    "messages1.append({\"role\": \"user\", \"content\": new_prompt})\n",
    "messages2.append({\"role\": \"user\", \"content\": new_prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the new chat completion requests\n",
    "response1 = client1.chat.completions.create(\n",
    "    model=model_name1,\n",
    "    messages=messages1,\n",
    "    max_tokens=2000 \n",
    ")\n",
    "response2 = client2.chat.completions.create(\n",
    "    model=model_name2,\n",
    "    messages=messages2,\n",
    "    max_tokens=2000 \n",
    ")\n",
    "result1 = response1.choices[0].message.content\n",
    "result2 = response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print the new results and compare them once again. If you want the models to make further changes in the codes, you can repeat the steps in the previous two code cells with a new prompt. Now we will generate an access token to collect the metrics values from each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "token = credential.get_token(\"https://management.azure.com/.default\")\n",
    "access_token = token.token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the last code cell, you need to copy the resource ID for your Azure AI Services from the Azure Portal. Go to the overview page of your Azure AI Services resource and select **JSON View**. Copy the Resource ID and replace the `Your resource ID` field below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the resource ID and the metric name\n",
    "resource_id = \"Your resource ID\"\n",
    "metric_name = \"TokenTransaction\"\n",
    "model_deployment_names = [\"gpt-4o\", \"gpt-4o-mini\"]\n",
    "\n",
    "# Calculate the timespan for the last 30 minutes\n",
    "end_time = datetime.now()\n",
    "start_time = end_time - timedelta(minutes=30) # Feel free to change timedelta to (hours=1), if necessary \n",
    "timespan = f\"{start_time.isoformat()}Z/{end_time.isoformat()}Z\"\n",
    "\n",
    "# Create the filter condition for multiple model deployment names\n",
    "filter_condition = \" or \".join([f\"ModelDeploymentName eq '{name}'\" for name in model_deployment_names])\n",
    "\n",
    "# Define the API endpoint with timespan and filter condition\n",
    "url = f\"https://management.azure.com{resource_id}/providers/microsoft.insights/metrics?api-version=2018-01-01&metricnames={metric_name}&timespan={timespan}&$filter={filter_condition}\"\n",
    "\n",
    "# Set the headers\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {access_token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check the response\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract time series data for each model deployment name\n",
    "    time_series_data = {}\n",
    "    for value in data['value']:\n",
    "        for timeseries in value['timeseries']:\n",
    "            model_name = timeseries['metadatavalues'][0]['value']\n",
    "            if model_name not in time_series_data:\n",
    "                time_series_data[model_name] = []\n",
    "            for data_point in timeseries['data']:\n",
    "                time_series_data[model_name].append((data_point['timeStamp'], data_point['total']))\n",
    "\n",
    "    # Plot the metrics over the timespan for each model deployment name\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for model_name, series in time_series_data.items():\n",
    "        timestamps, values = zip(*series)\n",
    "        plt.plot(timestamps, values, label=model_name)\n",
    "\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel('Processed Inference Tokens')\n",
    "    plt.title('Processed Inference Tokens Usage Over Time')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Failed to retrieve metrics:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "After reviewing the plot and remembering the benchmark values in the Accuracy vs. Cost chart observed before, can you conclude which model is best for your use case? Does the difference in the outputs' accuracy outweight the difference in tokens generated and therefore cost? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "If you've finished the exercise, you should delete the resources you have created to avoid incurring unnecessary Azure costs.\n",
    "\n",
    "1. Return to the browser tab containing the Azure portal (or re-open the [Azure portal](https://portal.azure.com?azure-portal=true) in a new browser tab) and view the contents of the resource group where you deployed the resources used in this exercise.\n",
    "1. On the toolbar, select **Delete resource group**.\n",
    "1. Enter the resource group name and confirm that you want to delete it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
