{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize your model (fine-tune)\n",
    "\n",
    "In this notebook, you'll generate a synthetic dataset and use it to evaluate the quality of your pre-trained model. \n",
    "\n",
    "## Before you start\n",
    "\n",
    "Install the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-evaluation promptflow wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize components\n",
    "\n",
    "Now you need to define the authentication values that will be used when submitting embeddings and chat completion requests through the API endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the base URL for your Azure OpenAI Service endpoint\n",
    "# Replace 'Your Azure OpenAI Service Endpoint' with your actual endpoint URL obtained previously\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = 'Your Azure OpenAI Service Endpoint'\n",
    "\n",
    "# Define the API key for your Azure OpenAI Service\n",
    "# Replace 'Your Azure OpenAI Service API Key' with your actual API key obtained previously\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = 'Your Azure OpenAI Service API Key'\n",
    "\n",
    "# Define the API version to use for the Azure OpenAI Service\n",
    "os.environ[\"OPENAI_API_VERSION\"] = '2024-08-01-preview'\n",
    "\n",
    "# Define the name of the model deployed in your Azure OpenAI Service\n",
    "os.environ[\"AZURE_OPENAI_DEPLOYMENT\"] = 'gpt-4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you need to prepare the text for generating the input to the simulator. You will perform a Wikipedia search and extract the first 5000 characters of the fetched page summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "\n",
    "# Prepare the text to send to the simulator\n",
    "wiki_search_term = \"Isaac Asimov\"\n",
    "wiki_title = wikipedia.search(wiki_search_term)[0]\n",
    "wiki_page = wikipedia.page(wiki_title)\n",
    "text = wiki_page.summary[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define callback function\n",
    "\n",
    "You can bring any application endpoint to simulate against by specifying a target callback function. In this case, you will use an application that is an LLM with a Prompty file: `application.prompty` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptflow.client import load_flow\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "async def callback(\n",
    "    messages: List[Dict],\n",
    "    stream: bool = False,\n",
    "    session_state: Any = None,  # noqa: ANN401\n",
    "    context: Optional[Dict[str, Any]] = None,\n",
    ") -> dict:\n",
    "    messages_list = messages[\"messages\"]\n",
    "    # Get the last message\n",
    "    latest_message = messages_list[-1]\n",
    "    query = latest_message[\"content\"]\n",
    "    context = latest_message.get(\"context\", None) # looks for context, default None\n",
    "    # Call your endpoint or AI application here\n",
    "    current_dir = os.getcwd()\n",
    "    prompty_path = os.path.join(current_dir, \"application.prompty\")\n",
    "    _flow = load_flow(source=prompty_path)\n",
    "    response = _flow(query=query, context=context, conversation_history=messages_list)\n",
    "    # Format the response to follow the OpenAI chat protocol\n",
    "    formatted_response = {\n",
    "        \"content\": response,\n",
    "        \"role\": \"assistant\",\n",
    "        \"context\": context,\n",
    "    }\n",
    "    messages[\"messages\"].append(formatted_response)\n",
    "    return {\n",
    "        \"messages\": messages[\"messages\"],\n",
    "        \"stream\": stream,\n",
    "        \"session_state\": session_state,\n",
    "        \"context\": context\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The callback function above processes each message generated by the simulator.\n",
    "\n",
    "Tasks performed by the function:\n",
    "\n",
    "* Retrieves the latest user message.\n",
    "* Loads a prompt flow from `application.prompty`.\n",
    "* Generates a response using the prompt flow.\n",
    "* Formats the response to adhere to the OpenAI chat protocol.\n",
    "* Appends the assistant's response to the messages list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the simulator\n",
    "\n",
    "You can now initialize the simulator and run it to generate synthetic conversations based on the provided text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from azure.ai.evaluation.simulator import Simulator\n",
    "\n",
    "model_config = {\n",
    "    \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"api_key\": os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    \"azure_deployment\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "}\n",
    "\n",
    "simulator = Simulator(model_config=model_config)\n",
    "    \n",
    "outputs = await simulator(\n",
    "    target=callback,\n",
    "    text=text,\n",
    "    num_queries=1,  # Minimal number of queries\n",
    ")\n",
    "\n",
    "output_file = \"simulation_output.jsonl\"\n",
    "with open(output_file, \"w\") as file:\n",
    "    for output in outputs:\n",
    "        file.write(output.to_eval_qr_json_lines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can review the output .jsonl file and see how the simulated conversation developed with each generated query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate simulation for groundedness\n",
    "\n",
    "Now that you have a dataset, you can evaluate the quality and effectiveness of your generative AI application. In this example, you will use groundedness as your quality metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import GroundednessEvaluator, evaluate\n",
    "\n",
    "groundedness_evaluator = GroundednessEvaluator(model_config=model_config)\n",
    "eval_output = evaluate(\n",
    "    data=output_file,\n",
    "    evaluators={\n",
    "        \"groundedness\": groundedness_evaluator\n",
    "    },\n",
    "    output_path=\"groundedness_eval_output.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the groundedness metric isn't close to 1.0, you can change the LLM parameters such as `temperature`, `top_p`, `presence_penalty` or `frequency_penalty` in the `application.prompty` file and re-run the notebook cells to generate a new dataset for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this exercise you created a synthetic dataset simulating a conversation between an user and a chat completion app. By using this dataset, you can evaluate the quality of your app's responses and fine-tune it to achieve the desired results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "If you've finished the exercise, you should delete the resources you have created to avoid incurring unnecessary Azure costs.\n",
    "\n",
    "1. Return to the browser tab containing the Azure portal (or re-open the [Azure portal](https://portal.azure.com?azure-portal=true) in a new browser tab) and view the contents of the resource group where you deployed the resources used in this exercise.\n",
    "1. On the toolbar, select **Delete resource group**.\n",
    "1. Enter the resource group name and confirm that you want to delete it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
